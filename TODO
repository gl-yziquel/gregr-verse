implicit union and intersection constructors
  are intersection constructors the same as record constructors? (and so unions are variants?)

type-inference algorithm
  do these dependently-typed terms have principal typings?  they don't need to; use CFA to deal with them
  can probably get away with it via syntactic embellishments or type annotations

dependent-typing functions can use (possibly run-time) partial evaluation / (JIT) abstract interpretation
  ex: sprintf :: (x::String) -> SPrintfType x

how to reconcile stack model of mutually-recursive linking?

procedure calls as module linking:
  [...cont...[inputs]] - push args, then enter module computation
  [...cont...|[inputs][output space?]...locals...] - reserve space for results?, perform local computation
  [...cont...[former inputs?][outputs]] - continue with output results

incorporate fully-parallelizeable procedures:
  expose outer and inner evaluation parallelism (argument evaluation vs. body evaluation)
  synchronization points to control parallelism and allow side-effects
  fundamental syntax: apply-parallel and apply-serial
  evaluation under lambda: partially applied procedures; when is it appropriate? (strict vs. lazy argument returns)
  reconcile complexities in coordination of application site provisions with procedure body dependencies

value-level (semi?)unification:
  why should the type-level have all the fun?
  procedure-app linking coordinator can reach upwards from pattern argument into constructor computation to pull out
  the true dependencies asynchronously to avoid having to wait for an artificial synchronization due to constructor app

data repr:
  data types from universes as in Conor McBride's ornaments paper
  records/modules
  structs/tuples
  arrays - ephemeral dynamic arrays via linear types
  inductive/coinductive algebraic type layer
  pointed/cyclic?/lifted/mutable/linear/shared

records:
  form of subtyping based on row-types, as in Morrow
  free extension without overwriting duplicate fields -- lexically scoped labels
  extension becomes like environment extension
  record field access -- constant-time lookup via implicitly-passed label->index args
  environments as records: variable lookup as field lookup
  closure and arguments as records
  procedure types can include parameter names (symbols):
    f : (one : A) -> (two : B) -> ...
    f one two = ...
  partially/fully apply procedure to arguments by name or position, even with non-flat procedures:
    call procedure with a record supplying arguments
    f : (one : A) -> (two : B) -> (three : C) -> ...
      by name:
        (f :@ {two=...}) : (one : A) -> (three : C) -> ...
      or by position
        (f :@ {2=..., 3=...}) : (one : A) -> ...
    proc could be non-flat; closure would simply store pending name/position fields until applicable
    the type says eventually there are named params: two and three
      f : (one : A) -> (two : B) -> (three : C) -> ...
      f one = ... computation here ... eventually return (proc two three = ...)
      essentially:
        (f :@ {three=val}) ==> proc one two = f one two val
        though maybe not implemented this way; with enough info, could be smarter and possibly finish computations
        that only depend on three early, even within the nested proc
        per-argument partial-application-handling code wrapped with closures to do this?
    if names and positions are mixed, positions should take precedence

modules: (how much of this is compatible with the above records?)
  asymmetric directed linking: one module's provisions are used to satisfy another's requirements
  symmetric mutually-recursive linking: combine requirements and provisions, but resolving mutually satisfied requirements
  mixins/traits become easy
  letrec explainable via dynamic module construction?
  procedure app explainable via very simple directed linking? allows targeted parameter applicaton? (ie. skipping of params)
  unresolve dependencies: should such computations be saved up until linking?
  dynamic 'opening' of modules: should specific symbols need to be specified?
  reflection/introspection/inspection of exposed fields; debugger/authority able to inspect private environment
  evaluating a module produces a record reflecting its top-level environment
  module form expands/evaluates all contained expressions within a new sub-module
    expressions are effectively evaluated line by line, so data constructions may not be mutually recursive without
    intervening thunks/indirections
    side-effectful code should be executed once, when the module body is evaluated; but when that is might be unpredictable
  define form creates a binding within the enclosing [sub]-module's top-level environment
    since these bindings are all placed in the same environment without extension, they are mutually-recursive

environments:
  environments are records:
    normally immutable, except in the case of module evaluation, during the evaluation itself?
    the residual record produced by the module evaluation should be immutable
  get-environment produces the current procedure environment as an immutable record:
    since a module's environment changes as the module is evaluated, define a get-namespace for grabbing a ref to it
    what about get-environment within a procedure defined in a module currently being evaluated? that will still break
      but such procedures can be considered different each time a new definition is linked to its parent module
      this "evolving" model can be implemented with lazy updates, only performing them when a procedure is demanded
      or, update could be performed when a procedure's dependencies are linked/updated
    another possibility: consider premature get-environment uses to be referencing undefined vars (in a way it does, right?)
      or the module environment can be considered the last definition of a module, so premature refs to it are undefined?
      or maybe implicit internal env access is a bad idea, and envs should only be accessible given a complete module in hand

alternative module/environment model:
  rejecting this idea for now; convenience of the "evolving" model seems to outweigh its complexity
  instead of insisting on modules essentially bootstrapping themselves into existence, consider them constructed externally
  though this will prevent the definition of macros alongside with their uses (this is something like phase-separation)
  separate issue: would be nice to be able to update module definitions and have their dependents re-link themselves
    doing this causes fissure with running code in the old module context; after all, module update should not be mutation

let, let-rec, let-seq via record construction and use/open:
  use ({x=...} :+: {y=...})
  use {x=..., y=...}
  use {x=...}; use {y=...}
  or not?  instead build a sub-module whose top-level defs are mutually recursive

type classes:
  static/dynamic dispatch based on records: 'case' involves destructor/continuation-record fields labeled with type/data tags
  ranging over values too; not just types
  allow projections, something like: ProjClass Type symbol
  class constraints a form of type function? based on records
  data-polymorphic views: streams vs. lists, type class interaction with case

case analysis:
  not just a static syntax compilation into nested switches
  pattern matching as selecting the field of a record containing destructors/continuations
  able to dynamically build efficient record-based matching as dependencies are satisfied

implicits:
  based on dynamically scoped parameters/keys (also see racket's initial values and preserves idea)
  open/closed contexts for accepting outside implicits (maybe all dynamic params too, not just implicits?)
  allow reinterpretation of type classes; eg. sorting w/ implicit Ord definition override

algebraic data:
  reified types as values (these are NOT data constructor tags)
    if a type contains value-level details, some of those details may be erasable at run-time
    ex. if we know that a particular Maybe value is always a Just, we can represent the value without a tag at run-time
    this is not limited to tags: if we know that a particular value is always [1, 2, 3], that value may be erasable as well
    of course, erasure should not be observable
  tags (these are not types, see above)
  constructors
  destructors

type tower:
  allow values to be raised to type-level computations, and vice-versa; generalizes upwards (kinds, etc.)
  how to fit in propositions?
  intersections/unions/subtyping/recursive types - avoid universal/existential quantification
  principal typing property: is it available under these circumstances?
  R-Acyclic Semi-unification
  dynamic checking = type checking occurs in tandem with evaluation (one step ahead?)
  recursive types due to mutually-recursive module linking still needs consideration
  type families: consider procedure that dynamically produces new types of the same form

syntax:
  context-sensitive syntactic values bound to variables (such as constructors); or should it be values, not variables?
  above explainable via syntactic records with context tags as field labels?
  partial macro expansion
  infix operator groups / relative ordering only within groups; ordering is nonsensical outside of groups

debugging:
  time-travel via reversible computations
  explicitly non-deterministic side effects allowable in parallel computations (to allow things like debug printing)

low-level:
  thread-local keys
  local data alloc
  linear values to describe ephemeral data
  non-allocating computations
  reversible/conservative computations
  local vs. global mutability; sharing
  exact/inexact/arbitrary precision
  synch/asynch channels
  ffi: i/o ports (including sockets?); unboxed arithmetic/comparison/conversion
  how to relate to miasm?
  parameterized performance/cost estimation
  equality saturation

example typing (ignoring free-ness of int-to-string and length):

f x = case x of
  Int i -> f (int-to-string i)
  String s -> length s

f:(x -> r) x = (case x of
  Int i -> (f:(a -> b) (int-to-string:(Int -> String) i:Int):String):b
  String s -> (length:(String -> Int) s:String):Int
  ):r

f : f?.(x -> r) :.

0{
x:i
i:Int
f:(a -> b)
a:String
b:
r:b
}
||
1{
x:s
s:String
r:Int
}

simplify:

f : f?.(x -> r) :.
0{
x:Int
f:(String -> r)
r:
}
||
1{
x:String
r:Int
}

link with free var f (itself!)
for each instance of f(small), link with f(big)
for single f(small) instance in env 0, choose f(big)'s env paths where the following holds when f(small):(String -> r):
note: only the input should be used to filter... can't filter based on output without possible unsoundness
x <: String
env 1 has no instances of f, otherwise each instance would choose its own appropriate paths to link with

therefore only env 1 path, choose fresh names:
(x1 -> r1) :.
{
x1:String
r1:Int
}
link with env 0 and unify fs, (x1 -> r1) = (String -> r):
x1 = String => String = String
r1 = r
0{
x:Int
f:(String -> r)
x1:String
r1:Int
r:r1
}
simplify (f no longer free; can be gc'ed):
0{
x:Int
r:Int
}

result is:
f : (x -> r) :.
0{
x:Int
r:Int
} # aka Int -> Int
||
1{
x:String
r:Int
} # aka String -> Int

or:
f : (Int -> Int) & (String -> Int) :. empty

