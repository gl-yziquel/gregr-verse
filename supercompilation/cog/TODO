===============================================================================
= more notes
===============================================================================
current tasks:
  editing
    wrap lam: a
      lam: works anywhere
      introducing new lams must also introduce lifting subst
    trim lam? not entirely necessary as it can be removed by application
      lam: only directly within a (value _)
        also works when body is a (value _), but needs to immediately substitute
      trimming a lam must eliminate bound var
      immediate-apply to the focus of another widget would be a better editing command than trim lam
    extract/copy closed term: e
    paste/replace focus using closed term widget 'count' positions to the right: E
    extract/match binder context to deal with open terms
    jump to binder from bvar: ENTER
    rename binder: ENTER
      readline hack to start?
      have workspace absorb digit state and remove keycount controller
      text entry/edit workspace mode: C-c/a/f/b/d/w/k, bspace, del, arrows, ENTER to finish
  other
    redo buffer: U
    C-c in general
    full ascend/descend: J, K
    jump to next/prev (): i/I

later tasks:
  deal with edit.rkt
  pull workspace.rkt apart, then rename *-model.rkt to *.rkt
  general REST-like DB interface
    get/put/post/delete
    url trees

===============================================================================
= older notes (but still important)
===============================================================================
DB/editor tasks:
  start with single term, reading/writing a single file
  maybe a racket #lang or macro in addition to the editor for bootstrapping/backup
  syntax-0-like markout presentation
    variable name capture: disambiguate
    if-0, if-1, pair-l, pair-r as functions, not syntax
    should this include special presentations for let, let*, letrec, etc? probably not for now
      done through lam/arg attr syntax
  module building/referencing, namespaces, "tagged context names" for term extraction and reincorporation
  commits and merges as consolidated revisions
    commit-only and merge-only branches
    auto-commit branches for collaboration
  multiple views of a term via sub-branches
    high-level/canonical vs. explanatory vs. optimized, etc.
  term views embedded in explanatory documents, wiki-style
    pull term into personal editor session; wrapped with url source/comment for reference
    open small or full editor inline in document; can connect to personal term/revision DB if desired
  "compiled" programs / editor scripts/config?

semantics:
  explicit substitution steps within values? would need a special pair constructor? maybe not do this
  environments
    binders, state/store (these are "permanent")
    everything else is separate (they go away after enough steps)
      state-accesses, reset/shift, produce
      concurrent computation (these may not be primitives)
        scheduling, interrupts, synch primitives, ipc
        could do this via produce/consume + low level machine models
    single "binders" construct
      in parallel, separated by class
  'denote' for binding bubbles: what do lambdas need to close over?
    a list of global indices for non-lam binders
  annotations (names/comments) for symbol/state/etc. binders
  generalize variables/references
    classes + indices?
    lam-param, symbol-ref, state-ref, (state-observation/access-result state-ref-index); state-access and state-assign?
  find CBV-equiv algo for reducing and equating terms with (in priority order): symbols, states - assignments - accesses, delimited control, concurrency
    (environment ... (value ...)) ==> float env upward (if possible)
    allow redundant introduction of effect binders; for showing equivalence with garbage-collected terms, backwards
  bubbling binders
    inspired by:
      http://fexpr.blogspot.ca/2014/04/why-is-beta-substitution-like-higgs.html
      http://fexpr.blogspot.ca/2014/03/continuations-and-term-rewriting-calculi.html
    unique symbols w/ comparison/identicality operator
    whole-term metavariables? maybe not; do this via reflection instead

===============================================================================
= editor ideas
===============================================================================
git-like branchable/mergeable hierarchical-groups
  group-level analogs to interaction-level operations
cursor-oriented interaction
  node types and syntax annotations (if/then/else) determine path traversal and presentation
vim-like tabs, "buffers", buffer-specific navigation (and help), command/search
  move between tabs; change tab position
  move between buffers; change buffer position; change layout/organization of all buffers in a given tab
dwarf-fortress-like hotkey/manual-select command menu with multiple detail levels (multiple ?-press toggles)
operations
  introduce (basic, existing (such as from another tab; not a copy), remembered)
  delete(q for quit)
  copy
  replace (basic, existing (move/copy), remembered)
  merge
  remember(w for write)
  mark (name a buffer or buffer-position/subterm)
  jump to mark (local or global)
buffers and "remembering" slots are both boxes for containing terms and both retain history of what terms they have contained (with truncation or exponential decay support?)
  buffers are interactively mutable, but "remembering" slots are inert and live in the background; you can write to these slots, but not interact with them directly
    otherwise, they're the same concept
      actually, let the slots save entire versions of a buffer interaction so that interaction history can also be preserved
workspaces, tabs, views
  active interactions (buffers), versioned interaction (files, "remember" slots)
    term-cursors
    histories store a sequence of (command, term-cursor)
    undo/redo linearization instead of branching history
      or not; copying suffices for this functionality
visualization aids
  syntax-0 presentaiton: bracketed vs. named vs. raw AST
  coloring
  annotation "terms"
  indirect referencing
  global, memoized referencing of
    substitutions, %uid
    large values (size determined bottom-up?) &uid
    (large?) closed lambdas #uid
  unnamed vars: $index
  named vars: name or name$index
clean substitutions
  hide irrelevant vars (name = name) and lifts
  bvar-relevance garbage collection
  ability to push substitution(s) down to bvars; ability to eliminate substitution(s) completely
    control scope of these operations by choosing top-level only, or also under lambdas

===============================================================================
= more rough ideas
===============================================================================
lambda introductions
  embed or wrap
    this dual pattern seems to apply to other compound expressions
  safe variable introductions only under an appropriate lambda
    boxes within a lambda/namespace
    but to start, allow unsafe?
    actually, lisa reminded me of another idea: proxy lambda wrappers
new interaction
  term interaction boxes and spaces
  begin a new box
    from primitive term/value
    copying an existing box
  move from box to box
  reposition boxes
    in main/large work area or onto/off-of a sidebar
  group boxes within hierarchical workspaces/directories
    shrink/expand both boxes and spaces
    name or assign bookmarks for easily jumping back and forth, expanding/shrinking nested spaces/boxes
    eventually also include other graphical widgets (produced/scripted by programs)
    also include remote/collaborative spaces
  refocus/move to subterm within a term
  manipulate subterm
    replace subterm
    refocus to [upward/downward] continuation from subterm
    execute subterm
    small step subterm
    big step subterm
  simplified aggregate expression histories for undo buffering
    interaction choices include replacements/wrappings or executions of terms
      traversing the choice-exploration tree
      returning to favorites/bookmarks in the tree
term copying/instantiation
  plain copies that are forgetful
  instantiations that remember their source and are notified of incompatible changes in the source
scripted instantiations via module-linking DSL
  DSL programs generated by usual interaction
scripted optimization strategies
optimization rule definition and lookup

===============================================================================
= priorities
===============================================================================
add lam/subst annotations/attributes
  for indicating preferred argument names, syntactic notes, presentation notes, interaction preferences, etc.
  annotations can probably also be encoded in quoted lambda terms and reflected into the raw lambda annotation during eval
syntax definitions
  printing (pretty or otherwise)
    present? presentation? presenting?
  parsing
encodings
  constructors
  recognizers
interaction
  simple idea to start with: improve interaction by coloring focus background
    probably requires custom pretty-printing of terms
bootstrapping; defining...
  data types
  modules
  other primitives?

===============================================================================
= current priorities
===============================================================================
high level syntax
  - tagged values and high level step, as described for syntax-1 below
  - include quoting/syntax-abstraction both before and after eval is defined

concrete syntaxes
  syntax-0 = concrete syntax for raw terms that elides action/value wrappers, with pretty substitutions
  syntax-0 step = single raw term step
  syntax-1 = concrete syntax for higher-level terms including only the following:
    - variables, syntax-1-tagged values
    - substitutions of only syntax-1-tagged values over a syntax-1 term
    - applications involving only other syntax-1 terms
  syntax-1 step = one unconditional syntax-0 step followed by as many syntax-0 steps as necessary to eliminate all non-syntax-1 terms
    - this may not always be possible: may hit an irreducible non-syntax-1 term
      - when starting with a syntax-1 term, this non-syntax-1 term should always end up being a value, thus terminating
        - unless there is a mistake in the design of syntax-1 primitives

very raw ideas
  pretty substitutions
    - provide penv with better names? s0, s1, etc.
    - condensed visual representation
      - name and memoize substitution binding sets
      - after propagating, refer to the subst bindings by name at each propagated position
      - toggle-able visibility of a substitution's binding set
        - toggle a variable term to show the value it will be substituted for
  quoting and syntactic abstraction
    - different data structures for concrete syntax and abstract syntax
      - concrete syntax resembles s-exprs, while abstract syntax represents term structure
    - "weak Kernel" idea: see the syntactic abstraction section
    some issues that will need to be solved for optimal presentation
      - clear but non-noisy indication of forms that will be treated as syntactic applications
      - converting between unprocessed and quoted forms for syntactic applications
        - automatic recognition and condensing of quoted forms that can be prettified
      - prettification of "eval" applied to quoted terms
        - they should be equivalent to unquoted terms, so take advantage of this
          - relies on having a proof of: forall T. T ~= eval (quote T)
  defining new data types
    - probably needs to be done at some meta-level
      - in order to guarantee unique tags
      - to provide abstraction guarantees
    - generated constructors/destructors can then be linked into modules
    - ad-hoc definition of new types would need to performed as an "effect"
  basic modules
    - need representations for
      - records, for representing symbol-to-value mappings
      - let-rec, for describing recursive module structures
    - see the high-level encoding notes a few sections below

program graph editor:
  look a few sections below
  implementation notes
    for AST annotations, describe them via paths descriptions rather than directly injecting decoration state into the AST itself
      - what I mean by path:
          annotate the term found by starting from the root and going left, right, left, left... etc.
      - allows diversity of presentations for the same AST
      - better for concurrency
      - easier to prove AST transformations correct
    factoring out sub-expressions:
      - push new substitution(s) upwards, in parallel
        - reverse application of explicit substitutions
      - eventually reify as a lambda application?
        - may only be necessary to cross upwards beyond other substitutions
          - that is, you form a lambda, let the upper subsitution cross you on its way down, then you keep moving up
      - probably need a beta reduction rule that allows substitution of an argument 'produce' term for a linear parameter in strict position
    syntactic issues
      - processing programs as data
        - keep in mind that programs are *not* text strings, though names may be
        - "concrete" syntax is made of lisp-like s-exprs
          - this form is produced by quoting of the program "text" and is what is passed as arguments to macros/fexprs
        - abstract syntax is made up of terms
          - this form is produced from concrete syntax and is what is actually manipulated by program transformations (such as eval)
          - this would be the form indicated by staging annotations (think MetaOCaml)
      - pretty presentation of terms involves
        - smart operator handling: moving from prefix form to other arbitrary forms
        - eliminating syntactic noise
        - effective spatial layout
        - highlighting and other decorations
    database representation
      - somewhat inspired by version-control, file systems, and the internet
      - each data object is immutable, with a UID (not necessarily a GUID)
      - hierarchical names as mutable references to data objects, somewhat like git branches
        - updates synchronized via compare-and-swap to guarantee update's intent
      - where do DB-based applications (text, gui, browser editors) store their state?
      - the hierarchical namespace is just a protocol that can be implemented in various ways
        - local persistence via disk
        - a remote machine's persistence accessed over the network
        - data services provided by local or remote applications
          - such as a term/program DB likely to be part of this program graph editor design...

================================================================
= syntactic abstraction
================================================================

this is somewhat inspired by the kernel language, but simpler for analysis
additional constructs can be satisfied entirely as a pre-processing phase, avoiding any complication of the calculus under study
syntax combinations evaluate operator, reify the operands, and leave behind a residual procedure application to be performed at runtime
  reification strategy for variables allows explicit evaluation via meta-circular interpretation
  macros defined as procedures that directly implement the desired effect via explicit evaluation
    more straightforward; application of a macro does NOT involve generating a quoted form that then needs expansion itself
    avoiding the quotation dance makes it easy to maintain hygene, but also easy to be unhygienic when intended

three additional constructs:
  syntax-lambda to bind a syntactic operator
    'application' of such an operator causes its argument expressions to be reified as data
  syntax-application to indicate that arguments should be reified, even if the operator was not bound by syntax-lambda
  standard-application to indicate that arguments should not be reified, even if the operator was bound by syntax-lambda

reification:
  keyword -> (pair 'keyword' (pair symbol symbol))
  variable -> (pair 'variable' (pair symbol evaluated-value)) ; this is key
  combination -> (pair 'combination' (list of reified expressions))
  reified environments map symbols to values, but only for variables being reified
    this makes information-flow analysis much simpler by avoiding unintentional capture
    if desired, broader or narrower environments specified manually to extend or limit variable capture beyond the default

explicit evaluation:
  no runtime support should be needed; can be implemented as a meta-circular interpreter with this reification strategy

===============================================================================
= effects by reflection
===============================================================================

Define effects as a consequence of a new term 'produce'.
  Previously, terms would only terminate when stuck, or after converging to a
  value.  The 'produce' term is a way of aborting a computation earlier, upon
  fully evaluating its argument.  The argument may then be interpreted by the
  meta-program (the program that is interpreting the program that has just
  halted on (produce v)) as an invocation of an external capability.  If this
  is intended, the invocation result should then be substituted for the
  (produce v) term, and the program resumed from that point.

  Depending on the meta-program capabilities and 'produce' communication
  protocol, this may enable effects such as i/o, mutable state,
  delimited control, concurrency... without complicating the fundamental
  theory.  Side-effectful extensions were originally planned to be implemented
  in entirely separate languages.  Now, effect handling becomes an orthogonal
  concern of certain host/meta-programs.

  It may seem as if this is punting on the hard work, but this approach is
  really just relocating it to a more appropriate context.  Rather than dealing
  with difficult theory for all programs, complications only need to be dealt
  with for the specific interpretations of 'produce' for which they are
  relevant.  A bonus of this approach is that we will also able to experiment
  with several effect system variations without having to reinvent the
  fundamental language each time.

- produce for i/o interaction and other effects
  - do we need unforgeable constants to securely represent capabilities when
    allocating/new-ref-ing?
    - or is it enough to check for absolute safety by verifying
      convergence/productivity of ref-allocating computation for all possible
      ref encodings that could be handed back to it?
      - attempts to cheat should always be foiled by this measure, since such
        programs have to guess a particular ref encoding, and shouldn't be able
        to guarantee they choose the right one every time

===============================================================================
= more interaction ideas
===============================================================================

- module-building syntax/mode/file-processing

- multi-hole/context editing and combining
  - free-hand inputting of new terms
    - 'transform': describe a function to be applied to current term
  - similar factoring primitives to those described in:
    http://worrydream.com/LearnableProgramming/

===============================================================================
= program graph editor
===============================================================================

manipulation:
  view and traverse space
    - maneuver to different term positions
    - visualize all or parts of terms
    - some form of structural diff and merge
  view and traverse time
    - something like sub-term evaluation tree thumbnail diagrams?
    - undo/redo transformations, revisit past evaluation steps
      - separate indication of the following transformations
        * deterministic steps (all contiguous steps part of the same thumbnail group)
        * non-deterministic steps (group by sub-term and contiguity of steps)
        * rewrites
        * complete replacements
    - view program transitions at flexible granularities
      - example: it should be possible to view program states corresponding to higher-level events, such as user interactions, video buffer refreshes, network events, etc.
      - this seems related to the programmable editing section
  manipulate terms
    - meaning-preserving transformations
      * evaluation steps
      * rewrites
      * conflict detection when historical dependencies change
        example:
          You reduce a term that depends on some binding.  Later, you change the binding.
          Warn if the former reduction would no longer produce the same result, as this may not be the programmer's intention.
    - introduce new terms
      - intelligent defaults for sub-terms
    - copy and replace terms
    - combine terms
      - example: build a compound term from existing sub-terms
    - lift out sub-expressions via functional or substitutional abstraction
    - abstract constants by replacing them with variable expressions with the intended meaning
      - example: focusing on the value of 'y'
        before
          x = 4; y = 20
        after
          x = 4; y = x * 5

navigation, visualization, organization:
  accessibility
    - configurable color palettes
    - optional multi-phased motions for increased precision
  prominently indicate the possible actions a programmer may take at any time
    - like a catalog of building blocks, list the primitive term/value components that may be instantiated
    - when choosing to perform an operation on existing components, make it apparent what components may be acted on
    - affordances
      - fixed arity terms show holes where subterms may be placed
      - n-ary terms allow insertion at any position, moving neighboring subterms out of the way
  visualize variable bindings
    - show the values all variables are bound to
      - replace substitution sets with names to reduce noise
    - show variables that are unbound
    - optionally show binding edges, connecting variable instances to their binder
  allow different versions of the same program to exist and be edited concurrently
    - it should be possible to move between these versions
    - different versions could be being edited simultaneously by multiple programmers
      - it should be possible to see what other programmers are currently doing or have done
  term organization and focusing
    - provide multiple workspaces
      - hierarchical or otherwise
      - share or move data/terms around between them
      - combine them
      - split them
      - possibly share with other programmers
    - allow several potentially-unrelated free-floating terms in a workspace
      - allow these to be grouped and moved around in groups
    - focus on subterms in-situ
    - pull out subterms into their own free-floating form that refers back to their position in the parent expression
    - hide or discard terms
      - completely hide to reduce clutter
      - make large or complicated terms less distracting by replacing them with a representative symbol
    - name and catalog terms and groups, free-floating or in-situ, for later search, retrieval and reference
    - identify multiple instances of the same term (copied or coincidentally identical)
  marks for jumping around more quickly
    - named
    - unnamed, stack-like, referenced by offset from head or tail
    - groupable, push/pop-able or saved/loaded by name
    - preserved under transformation where possible
  hierarchical naming and retrieval
    - hierarchy can describe categorizations, parent/child relation between terms, or other resource organizations
      - aside from terms, this should probably include the other editor elements, such as:
        - views themselves
          - views could be pointed either at terms, or at other views themselves to indicate the desire for some kind of soft-link-style sharing
        - marks
        - version history/pointers/logs
        - "compiled" programs
        - arbitrary non-term data
        - processes
    - sort of like urls; not really like a directory structure (parent and parent/child can both be terms/resources)
    - provides an intuitive organization, but doesn't reflect the exact data representation
      - for instance, significant amounts of associations and meta-data may be stored alongside the actual resources
        - potentially anything could be stored alongside
        - all without having to reify your meta organization in the hierarchy itself, as you might in a file system
    - support soft and hard linking
    - hierarchies should be easily duplicable/relocatable via grafting
    - should be publishable; should be able to refer to imported publications by something analogous to a hostname
      - imported publications should be mountable/graftable within your own local hierarchy
        - either as copies, or as live links to the remote source

programmable editing:
  example features
    - custom macros for automating common transformations
    - automation via pattern-matching
      - example: find all terms of form X and perform some transformation on them
  important properties to make these features possible
    - ability to recognize structures of interest
    - ability to compose transformations
    - ability to script other non-transformational editor behaviors
      - focusing
      - mapping controls/keys
      - remembering editor states
      - other forms of presentation/organization/book-keeping...

seamless meta-interpreter integration:
  recognize/visualize meaning of quoted terms
    - programs at meta-level N are treated as data by an interpreter at meta-level N+1
    - don't get stuck seeing these terms only as data
    - be able to manipulate these quotations as if they were the programs they represent
  prominently display meta-variables corresponding to the meta-interpreter's state with respect to terms
    - example: a meta-variable that reflects the state of a mutable store before and after some effectful term
  given an interpretation of 'produce' terms, can we automatically build useful visualizations that correspond to the interpreter's description of:
    - implicit or mutable state
    - control inversion
    - non-deterministic concurrency
    - etc?

===============================================================================
= high-level encoding
===============================================================================

- how to track function parameter names unintrusively?
  - maybe it's ok to annotate functions; interference with equalities probably
    won't occur in any meaningful way
- modules and linking
  - renaming imports/exports
  - narrowing exports
    - support both white and black listing of exported names
  - symmetric link/mix/combine
    - asymmetric linking of N + M can be implemented via: N + (M - N)
  - how to resolve mutually-recursive deps?
    - internally represent both cyclic and acyclic (over SCCs) dependency
      graphs?
  - should procedures also be packaged up with meta-data, like modules?
    - yes, at least include a basic type tag
  - parsing, syntax transformers and metacircular eval
    - partial fexprs aka "weak Kernel" (see the syntactic abstraction section)
    - syntax default (#%app)
    - setting the default
    - whitelist or blacklist names bound to syntactic operators

===============================================================================
= logic issues
===============================================================================

update:
  to have higher-order logic without types, the answer seems to be determining whether the embedding of a higher-order term (instantiating a higher-order quantified term) will produce a non-terminating propositional computation

- proof constructors
  - forall-term, forall-value (and somehow these may be
    mutually-recursive/inductive?
    - think: forall-term T. (P T) -> (value (lam T)))
  - forall-X and -> create new scopes, binding a meta-var or proof-reference
    that may be used within the internal proof
  - how to represent or? maybe full-blown sequents are valid
    - classical logic for describing program transformations may not prevent
      program terms themselves from encoding constructive logic

- non-termination theory
  - can function call termination analysis be accomplished without more special
    machinery than an induction rule over terms/values?

- reductio ad absurdum via hypothesis invalidation

===============================================================================
= reflection issues
===============================================================================

- how to load quoted code into meta environment?
  - consider the L+1 (meta) environment to be fixed
  - the L environment is being managed by L+1, and can have new code
    incorporated into it at that level already
  - should this be done by re-seating the entire process?
  - is there some explainable way to do it iteratively?

===============================================================================
= pretty old effect system ideas
===============================================================================

- analysis of concurrency with shared memory
  - track set of escaped minimal embeddings of mutable cells to prove
    properties in the presence of concurrency
  - example:
    - thread T reads from cell M
      - assume set of escaped minimal M embeddings contains only E[M]
    - what can be written to cell M, forall S. S[E[M]] ? these are the only
      things that need to be considered readable in thread T
      - show that under the assumption of thread T making no progress (after
        all, it's waiting to read and may be holding a "lock" that affects
        other threads' behaviors with respect to M), S[E[M]] either:
        - embeds (write M x) for a finite set of possible x; these are the only
          x's that thread T may end up reading in
        - does not embed (write M x); special case of the above
        - diverges before any (write M x)
      - without such proof, must assume: forall v. (write M v); this means
        thread T could read anything in

- shift/reset
  - when encountered, reset marks the log, and pushes its one-hole-context
  - when providing a value to the reset ohc, the result should be skeptical of
    any obligations incurred since the log marking, as these obligations could
    hide shifts
    - if obligations can't be analyzed to tell if they contain shift, reset's
      result should be an obligation that resumes this investigation when
      evaluated
  - btw, shift should not capture return-context

===============================================================================
= old ideas (if I bring these back, it will be in a different context)
===============================================================================

; note: propositions really describe properties of full computational states,
;       not just thunks: catalog is implicit in the following
; TODO: [how] should we represent quantifiers?
; TODO: can negation instead be nicely generalized as 'False' implication?
;       then generalize [con/di]vergence using negation, ===>, and quantifiers

prop = thunk ==> thunk  ; step relation (==>* for reflexive transitive closure)
     | converges thunk atom  ; thunk terminates with atom as result
     | diverges thunk  ; thunk fails to terminate or produces an error
     | thunk === thunk  ; judgmentally equal thunks (commutative)
     | atom == atom  ; judgmentally equal (commutative)
     | atom != atom  ; judgementally unequal (commutative)
     | type value-type atom  ; type constraint on atom

thunk = (term, env)

atom = unit | bit-0 | bit-1 | indirect UID | promise UID

value-type = Unit | Bit | Pair | Lam


derived props such as:
  thunk0 ==>* thunk1, where
    thunk0 === thunk1 OR
    thunk0 ==> thunk1 OR
    thunk0 ==>* thunkX AND thunkX ==>* thunk1
  thunk ===> atom, equivalent to something like:
    thunk ==>* ((val-a atom ; halt), ENV)

contradictions produced by
  converges and diverges props for the same thunk
  == and != for the same pair of atoms
  multiple type constraints for the same atom

implications in the prop framework defined as meta-level lambdas
props are then data processed and produced by meta-level programs


new machinery
  catalogs now include propositions, describing hypotheses and/or inferences
    hypotheses are introduced at the meta-level by implications
  prop contradiction eliminates the current state from set of possibilities
  separate forcing/updating of delayed thunks from parent computation state
    you evaluate the thunk against the halt continuation
      but with the parent catalog
  lambda skolemization introduces new catalog frame: parent frame is read-only
  case splitting duplicates catalog frame for each new state case
  case splitting allows conjectures of the following forms:
    value-type cases
      the type of a promise is speculated before type-dependent evaluation
        (in the case of pair-access for bits/pairs or application for lams)
      each value-type conjecture starts a new hypothetical world/state
      as far as i can see, this will finally result in three situations:
        all cases converge, type splitting was unnecessary
        all cases diverge, type splitting did not save us
        only one case converges, type splitting made a difference
      no special term rebuilding necessary for this type of split
    bit-0 vs. bit-1
      this corresponds to exploring conditional branches
      each hypothetical world is rebuilt as a branch of a new conditional
    converge vs. diverge
      this corresponds to obligations for evaluating potentially-unused thunks
      if convergence cannot be proven for a thunk, a program is obligated
        to evaluate it even if its result is never used
      this obligation is reflected during term rebuilding
      proving divergence for a program thunk implies full program divergence
  observations about evolving converge/diverge hypotheses during evaluation
    corresponds to generating an obligation and promise
    as the thunk unwinds, the potentially-diverging part contracts
    contraction results in a new case split
      new diverging case obviates the original case split entirely
      new converging case contradicts original diverging case, eliminating it
      so, only the new child split/obligation remains
  for term rebuilding
    may need to keep a mapping of representative thunks for promises:
      promise UID -> (thunk OR skolem)
      the thunk introducing a promise is its representative

===============================================================================
= older ideas
===============================================================================

 eager and lazy CBV operational semantics
   CBV describes observable semantics while lazy/eager describes operational strategy
 eager CBV
   constructors with args need to save one-hole contexts
   all terms in focus are evaluated to completion with result values being catalogued
 lazy CBV
   constructors with args do not save any one-hole contexts
     they can punt on evaluating their args
     punted terms are paired with current environment and catalogued as eval obligations
   rewinding to evaluate an obligation
     pop catalog entries until desired key is found
     save popped entries (in reverse) with old context
     begin evaluating a new state with the remaining catalog
       (state clg-oblig-term (return-context (old-cont old-env reversed-entries)) clg-oblig-env)
     when returning to former context, re-push its entries onto the new catalog
   the catalog as described is actually a special case of a more general 'effect log'
     entry types can be added for memory allocation and writes
 given a catalog partitioning at any event boundary: members of older part do not depend on members of newer
   minimize duplication when splitting worlds around a hypothetical equality
     assumption boundary must be made before any key that would depend on it
       given key D being guessed
         assumption entry must be made before first E depending on D's value
         there may be entries between D and its assumption entry
           this would be because they depend on D's effects, but don't depend on D's value
       if made earlier than existing assumption, must split the splits
         this will happen with out-of-order case analysis on opaque values:
           first, case-analysis occurs on some D that happens to depend on C
           later, in one branch of (case D), retroactive case-analysis occurs on C
           the case-analysis on C must be pulled above that of D
             C's assumption entry must be made earlier than D's entry
             new split muts be made earlier than existing split, duplicating that split
             some waste produced (hopefully only temporarily) for the branch of D not analyzing C
       older keys definitely don't depend on assumption and make up the old region
       newer keys that happen to also not depend on assumption may be moved across it into the old region
         moving across also requires no effect dependencies
       old region ends up shared by both hypothetical worlds
   cleaning up after a transformation attempt on a subterm
     when producing result, only need to garbage collect entries newer than the subterm
   there should be a single key allocator so that every value, even across partitions/worlds, has a unique key
     when partitioning based on hypothetical equality, copy all keys dependent on assumed value
       when re-combining worlds, new world only contributes keys newer than split
 assumptions in effect log mark when the world split
   new world not responsible for old effects, though may evaluate them under assumptions to see what they would provide
   when re-combining with old world, only effects after assumption are contributed
   after re-combining, assumptions are used to unify target keys and generate code to define new keys
 diagram:
   example of optimal assumption placement
   case D, where e's depend on D, c's do not depend on D at all, x's depend only on D's effect
 newer ---------------------------------- older
 ... e e e e (assume D = _) x x x D c c c c ...

 future small-step ideas
(data assumption
  (assume-eq (key0 key1))
  (assume-neq (key0 key1))
  (assume-value (key new-keys value)))
(data clg-entry
  (clg-data (kvs)))   plural, allowing SCCs (let-rec) to satisfy partition property
  (clg-obligation (key term env notes))
  (clg-assumption (assumed)))
  (clg-memory-effect ())
  (clg-stream-effect ())
  (clg-reset (marker))
  etc.
(data cont
  (ohc (cont oh))
  (halt ())
  (return-caller (cont env)))
  (return-context (cont env clg-replay)))

===============================================================================
= Domain-specific programming tools
===============================================================================

http://www.evanmiller.org/dont-kill-math.html

can accept that code is made up of symbols
  this is acknowledged in drawing dyn viz
  whether or not the code is represented as plain text, or in a more diagrammatic way
having to comprehend the generalizations described by code simply by reading text and simulating the behavior in your mind involves super-human effort and should be unnecessary; comprehension of the concrete is direct and often effortless (exceptions involve data too large for the mind, requiring exploration/navigation; but this is still not an unnatural effort)
  should comprehension of code be made more direct by interactively visualizing the program's transformation as concrete data flows through it? is there a better approach than this?
output/effect of running code is concrete
code is currently written directly
why not instead write code with tools for manipulating the concrete, then generalizing?
  leverage the directness of the concrete medium to know what output you'll be getting with much more certainty
  explicit generalization by indicating/marking important concrete features and their relationships
  tools for implicit generalization probably involve machine learning
is symbolism unavoidable for manipulating the abstract?
  you can describe values concretely given enough context
  can you describe actions/operations concretely?
    as machines? but how do you describe these machines without even more context?
    for instance, a specific pixel drawing requires only a grid of colored pixels
      these additional concepts seem to be symbols, reinvented
    even if you don't agree that you need to reinvent symbols to describe machines, once you are dealing with machines you are back where you started: the problem of having to simulate their behavior to perform analysis
      it seems the best we can do is provide tools that assist with this simulation?

===============================================================================
= Summary of summaries of http://worrydream.com/LearnableProgramming/
===============================================================================

The environment should allow the learner to:
  read the vocabulary -- what do these words mean?
    The environment should make meaning transparent, so the learner can concentrate on high-level concepts, not vocabulary.
    The environment should explain in context. Show and tell. Annotate the data, not just the code.
  follow the flow -- what happens when?
    The environment can make flow tangible, by enabling the programmer to explore forward and backward at her own pace.
    The environment can make flow visible, by visualizing the pattern of execution.
    The environment can represent time at multiple granularities, such as frames or event responses, to enable exploration across these meaningful chunks of execution.
  see the state -- what is the computer thinking?
    The environment must show the data. If a line of code computes a thing, that thing should be immediately visible.
    The environment must show comparisons. If a program computes many things, all of those things should be shown in context. This is nothing more than data visualization.
    The system must have no hidden state. State should either be eliminated, or represented as explicit objects on the screen. Every action must have a visible effect.
  create by reacting -- start somewhere, then sculpt
    The environment must be designed to get something on the screen as soon as possible, so the programmer can start reacting. This requires modeling the programmer's thought process, and designing a system that can pick up on the earliest possible seed of thought.
    The environment must dump the parts bucket onto the floor, allowing the programmer to continuously react to her raw material and spark new ideas.
  create by abstracting -- start concrete, then generalize
    The environment should encourage the learner to start constant, then vary, by providing meaningful ways of gradually and seamlessly transitioning constant expressions into variable expressions.
    The environment should encourage the learner to start with one, then make many, by providing ways of using those variable expressions at a higher level, such as function application or looping.

The language should provide:
  identity and metaphor -- how can I relate the computer's world to my own?
  decomposition -- how do I break down my thoughts into mind-sized pieces?
  recomposition -- how do I glue pieces together?
  readability -- what do these words mean?
